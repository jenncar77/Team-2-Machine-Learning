{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "324bedb7-4cc6-4c8b-865e-c6765158199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61cd7b8e-fe4d-4ac4-bf96-9eea26e5fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/buboyencarnacion\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {working_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "708acd5e-2635-4162-8a78-b0d0a851a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "customers_df = pd.read_csv(os.path.join(working_directory, 'updated_customers_data.csv'))\n",
    "products_df = pd.read_csv(os.path.join(working_directory, 'updated_products_data.csv'))\n",
    "transactions_df = pd.read_csv(os.path.join(working_directory, 'updated_transactions_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b755a2e1-3616-4fca-abe7-e84e093e0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning the Datasets ###\n",
    "\n",
    "# Products: Clean 'Product_Price' (remove \"Php\" and convert to numeric)\n",
    "products_df['Product_Price'] = products_df['Product_Price'].replace('[\\\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Transactions: Standardize 'Transaction_Date' and handle missing values\n",
    "transactions_df['Transaction_Date'] = pd.to_datetime(transactions_df['Transaction_Date'], errors='coerce')\n",
    "\n",
    "# Fill missing numerical values in Transactions\n",
    "transactions_df.fillna(transactions_df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Customers: Handle missing values\n",
    "customers_df.fillna(customers_df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "977221b8-1ad4-4127-8cf6-d456a6af1b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Descriptive Statistics:\n",
      "       Company_ID          Company_Name  Company_Profit  \\\n",
      "count         100                   100      100.000000   \n",
      "unique         91                   100             NaN   \n",
      "top       Unknown  Tech  Enterprises  1             NaN   \n",
      "freq           10                     1             NaN   \n",
      "mean          NaN                   NaN    76268.620000   \n",
      "std           NaN                   NaN    25590.952639   \n",
      "min           NaN                   NaN    30663.000000   \n",
      "25%           NaN                   NaN    54984.250000   \n",
      "50%           NaN                   NaN    75301.500000   \n",
      "75%           NaN                   NaN    99467.250000   \n",
      "max           NaN                   NaN   118114.000000   \n",
      "\n",
      "                                             Address Profitability_Category  \\\n",
      "count                                            100                    100   \n",
      "unique                                            97                      3   \n",
      "top     Ayala Avenue, Brgy. 101, Baguio, Philippines                 Medium   \n",
      "freq                                               2                     58   \n",
      "mean                                             NaN                    NaN   \n",
      "std                                              NaN                    NaN   \n",
      "min                                              NaN                    NaN   \n",
      "25%                                              NaN                    NaN   \n",
      "50%                                              NaN                    NaN   \n",
      "75%                                              NaN                    NaN   \n",
      "max                                              NaN                    NaN   \n",
      "\n",
      "               Region  \n",
      "count             100  \n",
      "unique             32  \n",
      "top      Barangay 202  \n",
      "freq               11  \n",
      "mean              NaN  \n",
      "std               NaN  \n",
      "min               NaN  \n",
      "25%               NaN  \n",
      "50%               NaN  \n",
      "75%               NaN  \n",
      "max               NaN  \n",
      "\n",
      "Products Descriptive Statistics:\n",
      "       Product_ID        Product_Name  Product_Price Price_Range\n",
      "count          20                  20      20.000000          20\n",
      "unique         19                  20            NaN           2\n",
      "top       Unknown  FinPredictor Suite            NaN        High\n",
      "freq            2                   1            NaN          16\n",
      "mean          NaN                 NaN  134680.000000         NaN\n",
      "std           NaN                 NaN   39408.916971         NaN\n",
      "min           NaN                 NaN   84000.000000         NaN\n",
      "25%           NaN                 NaN  100800.000000         NaN\n",
      "50%           NaN                 NaN  131600.000000         NaN\n",
      "75%           NaN                 NaN  159600.000000         NaN\n",
      "max           NaN                 NaN  224000.000000         NaN\n",
      "\n",
      "Transactions Descriptive Statistics:\n",
      "         Unnamed: 0  Transaction_ID    Company_ID    Product_ID      Quantity  \\\n",
      "count  10000.000000    10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean    4994.394200     5005.159800     50.525200     10.402100     10.575900   \n",
      "min        0.000000        1.000000      1.000000      1.000000      0.000000   \n",
      "25%     2769.750000     2777.750000     28.000000      6.000000      6.000000   \n",
      "50%     4997.500000     5005.000000     50.000000     10.000000     11.000000   \n",
      "75%     7194.250000     7253.250000     73.000000     15.000000     15.000000   \n",
      "max     9999.000000     9999.000000    100.000000     20.000000     21.000000   \n",
      "std     2737.250768     2746.396292     27.418179      5.473939      5.511794   \n",
      "\n",
      "                    Transaction_Date  Product_Price    Total_Cost  \\\n",
      "count                           2520   10000.000000  1.000000e+04   \n",
      "mean   2022-10-22 12:40:00.000000256  134317.300635  1.416222e+06   \n",
      "min              2020-10-29 00:00:00   75613.362923  8.400000e+04   \n",
      "25%              2021-10-24 00:00:00  102896.408099  7.560000e+05   \n",
      "50%              2022-10-28 12:00:00  131297.783516  1.344000e+06   \n",
      "75%              2023-10-17 00:00:00  158898.458143  1.881600e+06   \n",
      "max              2024-10-28 00:00:00  246279.050335  4.480000e+06   \n",
      "std                              NaN   37067.236838  8.623310e+05   \n",
      "\n",
      "            Recency  Purchase_Frequency  Total_Spending  \n",
      "count  10000.000000        10000.000000    1.000000e+04  \n",
      "mean     732.005000           81.788400    1.288110e+08  \n",
      "min        0.000000           60.000000    8.655360e+07  \n",
      "25%      730.500000           77.000000    1.200976e+08  \n",
      "50%      730.500000           82.000000    1.278984e+08  \n",
      "75%      730.500000           86.000000    1.364608e+08  \n",
      "max     1460.000000          107.000000    1.756160e+08  \n",
      "std      209.237413            8.029836    1.497129e+07  \n"
     ]
    }
   ],
   "source": [
    "### Descriptive Statistics ###\n",
    "\n",
    "# Generate descriptives for each dataset\n",
    "customers_desc = customers_df.describe(include='all')\n",
    "products_desc = products_df.describe(include='all')\n",
    "transactions_desc = transactions_df.describe(include='all')\n",
    "\n",
    "# Save cleaned datasets\n",
    "customers_df.to_csv(os.path.join(working_directory, 'cleaned_customers_data.csv'), index=False)\n",
    "products_df.to_csv(os.path.join(working_directory, 'cleaned_products_data.csv'), index=False)\n",
    "transactions_df.to_csv(os.path.join(working_directory, 'cleaned_transactions_data.csv'), index=False)\n",
    "\n",
    "# Print descriptives\n",
    "print(\"Customers Descriptive Statistics:\")\n",
    "print(customers_desc)\n",
    "\n",
    "print(\"\\nProducts Descriptive Statistics:\")\n",
    "print(products_desc)\n",
    "\n",
    "print(\"\\nTransactions Descriptive Statistics:\")\n",
    "print(transactions_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c59c5ea6-6b94-4617-8d8d-ef56db2cb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert IDs to String and Ensure No Missing Values:\n",
    "# Convert Product_ID to string in both datasets\n",
    "products_df['Product_ID'] = products_df['Product_ID'].astype(str)\n",
    "transactions_df['Product_ID'] = transactions_df['Product_ID'].astype(str)\n",
    "\n",
    "# Convert Company_ID to string in both datasets\n",
    "customers_df['Company_ID'] = customers_df['Company_ID'].astype(str)\n",
    "transactions_df['Company_ID'] = transactions_df['Company_ID'].astype(str)\n",
    "\n",
    "# Ensure no missing values in key columns\n",
    "assert not transactions_df[['Product_ID', 'Company_ID']].isnull().any().any()\n",
    "assert not customers_df[['Company_ID']].isnull().any().any()\n",
    "assert not products_df[['Product_ID']].isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d01c01e7-d9ad-41a7-88be-23f71dfe19aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "   Transaction_ID Company_ID Product_ID  Quantity Transaction_Date  \\\n",
      "0             1.0       88.0        6.0      11.0       2024-03-26   \n",
      "1             2.0       29.0       19.0      16.0              NaT   \n",
      "2             4.0       85.0       12.0      12.0              NaT   \n",
      "3             5.0       47.0        3.0       8.0              NaT   \n",
      "4             6.0       80.0       11.0       4.0       2021-07-12   \n",
      "\n",
      "   Product_Price_x  Total_Cost  Recency  Purchase_Frequency  Total_Spending  \\\n",
      "0    194379.147964   1075200.0    216.0                82.0     128878400.0   \n",
      "1     97930.993380   1428000.0    730.5                69.0     121996000.0   \n",
      "2    131297.783516   1008000.0    730.5                89.0     126061600.0   \n",
      "3     99575.609634    705600.0    730.5                60.0      86553600.0   \n",
      "4    160658.675350    627200.0   1204.0                90.0     150315200.0   \n",
      "\n",
      "           Product_Name  Product_Price_y Price_Range           Company_Name  \\\n",
      "0  RevenueVue Dashboard         179200.0        High    Elite Consulting 88   \n",
      "1      EcoNomix Modeler          95200.0      Medium    Sky  Industries  29   \n",
      "2      BudgetMaster Pro          84000.0      Medium      Green Ventures 85   \n",
      "3  TrendWise Forecaster         100800.0        High  Green  Industries  47   \n",
      "4   OptiFlow Automation         156800.0        High    Green  Partners  80   \n",
      "\n",
      "   Company_Profit                                            Address  \\\n",
      "0         75950.0            EDSA, Barangay 456, Taguig, Philippines   \n",
      "1         61952.0              Edsa, brgy. 606, makati, philippines!   \n",
      "2        113470.0         EDSA, Barangay 707, Cebu City, Philippines   \n",
      "3         31130.0   Taft Ave, Barangay 707, Mandaluyong, Philippines   \n",
      "4        111227.0  Commonwealth Ave, Barangay 202, Manila, Philip...   \n",
      "\n",
      "  Profitability_Category         Region  \n",
      "0                 Medium   Barangay 456  \n",
      "1                 Medium      brgy. 606  \n",
      "2                   High   Barangay 707  \n",
      "3                    Low   Barangay 707  \n",
      "4                   High   Barangay 202  \n"
     ]
    }
   ],
   "source": [
    "# Merge Datasets\n",
    "# Step 1: Merge Transactions with Products on 'Product_ID'\n",
    "merged_df = transactions_df.merge(products_df, on='Product_ID')\n",
    "\n",
    "# Step 2: Merge the result with Customers on 'Company_ID'\n",
    "merged_df = merged_df.merge(customers_df, on='Company_ID')\n",
    "\n",
    "# Drop unnecessary columns (optional)\n",
    "merged_df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Save the merged dataset (optional)\n",
    "merged_df.to_csv(os.path.join(working_directory, 'merged_dataset.csv'), index=False)\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "090d6477-d3e5-4855-a3bc-e112607ca629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Merged DataFrame:\n",
      "Transaction_Date    6199\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/ghyqsycn5z34j1zd_gpjk9bw0000gn/T/ipykernel_12297/3355706019.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[col].fillna(merged_df[col].median(), inplace=True)\n",
      "/var/folders/yw/ghyqsycn5z34j1zd_gpjk9bw0000gn/T/ipykernel_12297/3355706019.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df[col].fillna(merged_df[col].mode()[0], inplace=True)\n",
      "/var/folders/yw/ghyqsycn5z34j1zd_gpjk9bw0000gn/T/ipykernel_12297/3355706019.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Address Missing Data in the Merged Dataset\n",
    "# Check for missing values\n",
    "missing_values = merged_df.isnull().sum()\n",
    "print(\"\\nMissing Values in Merged DataFrame:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Numerical columns: Continuous and Count Data\n",
    "# Use median for imputation\n",
    "for col in merged_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    merged_df[col].fillna(merged_df[col].median(), inplace=True)\n",
    "\n",
    "# Categorical columns: Impute with the mode\n",
    "for col in merged_df.select_dtypes(include=['object']).columns:\n",
    "    merged_df[col].fillna(merged_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Date columns: Forward-fill or backward-fill for imputation\n",
    "merged_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Validate that missing data is resolved.\n",
    "assert not merged_df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afc9ab40-820e-4cd3-844d-25588e9f0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Feature Engineering and Machine Learning Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d692598-4398-429a-839a-3324d54a9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged dataset\n",
    "merged_df = pd.read_csv(os.path.join(working_directory, 'merged_dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b234715-976b-4831-a9b9-9e0a0cd76b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and Target Prepared\n"
     ]
    }
   ],
   "source": [
    "### Feature Engineering ###\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = merged_df.drop(columns=['Product_ID'])\n",
    "y = merged_df['Product_ID']\n",
    "\n",
    "# Convert target variable to categorical (if necessary)\n",
    "y = y.astype('category')\n",
    "\n",
    "# One-Hot Encoding for Categorical Columns\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Scale Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Final Check: Ensure all features are processed\n",
    "print(\"Features and Target Prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69711095-112c-498f-a88a-3cedd8f18e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split Data ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a0dbbf7-f149-413f-b0b6-bec3f40b7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Logistic Regression Results:\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        85\n",
      "         2.0       1.00      1.00      1.00        86\n",
      "         3.0       1.00      1.00      1.00        84\n",
      "         4.0       1.00      1.00      1.00        97\n",
      "         5.0       1.00      1.00      1.00        90\n",
      "         6.0       1.00      1.00      1.00        81\n",
      "         7.0       1.00      1.00      1.00        78\n",
      "         9.0       1.00      1.00      1.00        72\n",
      "        10.0       1.00      1.00      1.00       270\n",
      "        11.0       1.00      1.00      1.00        91\n",
      "        12.0       1.00      1.00      1.00        67\n",
      "        13.0       1.00      1.00      1.00        83\n",
      "        14.0       1.00      1.00      1.00        78\n",
      "        15.0       1.00      1.00      1.00        72\n",
      "        17.0       1.00      1.00      1.00        92\n",
      "        18.0       1.00      1.00      1.00        69\n",
      "        19.0       1.00      1.00      1.00        86\n",
      "        20.0       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00      1661\n",
      "   macro avg       1.00      1.00      1.00      1661\n",
      "weighted avg       1.00      1.00      1.00      1661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Model 1: Multinomial Logistic Regression ###\n",
    "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_report = classification_report(y_test, logistic_predictions)\n",
    "\n",
    "print(\"\\nMultinomial Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {logistic_accuracy}\")\n",
    "print(logistic_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e644c2-f8e3-46e0-8432-f9685092e267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
